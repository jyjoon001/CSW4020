{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSW4020_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2D3KE5jITY1Q",
        "iKbvbSAvjmMT",
        "zQDd-FOcyYY-",
        "Vef31meEygKF",
        "l7fAkU7yyBSz",
        "FZORBSAvp9tC",
        "xkf9lwlP8haF",
        "A5C8VBEAVsaL"
      ],
      "authorship_tag": "ABX9TyPptDOUlAlm6EKl3YYPyj/T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyjoon001/CSW4020/blob/main/CSW4020_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoKbIB0QBdMv"
      },
      "source": [
        "# 기말고사 대비용 Jupyter Notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTP8xT2yChS5"
      },
      "source": [
        "!pip install konlpy\n",
        "import nltk\n",
        "import re\n",
        "import random\n",
        "nltk.download('book')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('words')\n",
        "from nltk.book import *\n",
        "from nltk.corpus import brown\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk.corpus import inaugural\n",
        "from nltk.corpus import PlaintextCorpusReader\n",
        "from nltk.corpus.reader.plaintext import CategorizedPlaintextCorpusReader\n",
        "names = nltk.corpus.names\n",
        "from nltk.corpus import movie_reviews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1q5hsaeDVGw",
        "outputId": "1ab52393-f8ba-4149-f4ec-06abfdce590e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/CSW4020"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/CSW4020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D3KE5jITY1Q"
      },
      "source": [
        "#정보처리및자연어처리 2차과제\n",
        "> 20161482 박준용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5-FgZnEKzox"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import PlaintextCorpusReader\n",
        "from nltk.corpus.reader.plaintext import CategorizedPlaintextCorpusReader\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3-ufd5hTY1S"
      },
      "source": [
        "##1번: 배점 5점\n",
        "\n",
        "다음을 수행하여 변수 tagged_paragraphs 를 만드시오. \n",
        "1. data.txt 불러오기\n",
        "2. 본문 영역 (```<body>``` … ```</body>```) 내 문단 단위 (```<p>```… ```</p>```)로 구분 된 어절과 형태분석 쌍의 튜플을 원소로 하는 리스트 구성\n",
        "\n",
        "*   tagged_paragraphs = [[문단1] , [문단2], [문단3], ….]\n",
        "*   각 문단 = [(어절1, 형태분석1), (어절2, 형태분석2), …]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhCmbh2nTY1S"
      },
      "source": [
        "# 1번\n",
        "data = open('./data.txt', encoding = 'utf-8').read()\n",
        "body = re.search('<body.*/body>', data, re.I|re.S).group()\n",
        "p = re.findall('<p.*?/p>', body, re.I|re.S)\n",
        "tagged_paragraphs = []\n",
        "for i in range(0, len(p)):\n",
        "    temp1 = re.findall(r'\\t(.*?)\\n',p[i])\n",
        "    temp2 = [tuple(re.split(r'\\t+', w)) for w in temp1]\n",
        "    tagged_paragraphs.append(temp2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrNCmse9TY1S",
        "outputId": "b656bed3-6537-43af-b76f-eaca1389c929"
      },
      "source": [
        "print(tagged_paragraphs[2:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[('내', '나/NP + 의/JKG'), ('머릿속으로', '머릿속/NNG + 으로/JKB'), ('어떤', '어떤/MM'), ('장면이', '장면/NNG + 이/JKS'), ('떠오른', '떠오르/VV + ㄴ/ETM'), ('것은', '것/NNB + 은/JX'), ('그', '그/MM'), ('어느', '어느/MM'), ('순간이었다.', '순간/NNG + 이/VCP + 었/EP + 다/EF + ./SF'), ('그것은', '그것/NP + 은/JX'), ('확실히', '확실히/MAG'), ('좀', '좀/MAG'), ('엉뚱한', '엉뚱/XR + 하/XSA + ㄴ/ETM'), ('연상이었으므로', '연상/NNG + 이/VCP + 었/EP + 으므로/EC'), ('나는', '나/NP + 는/JX'), ('나도', '나/NP + 도/JX'), ('모르게', '모르/VV + 게/EC'), ('피식', '피식/MAG'), ('웃었다.', '웃/VV + 었/EP + 다/EF + ./SF'), ('내', '나/NP + 의/JKG'), ('웃음은', '웃음/NNG + 은/JX'), ('채', '채/MAG'), ('형태를', '형태/NNG + 를/JKO'), ('갖추지', '갖추/VV + 지/EC'), ('못한', '못하/VX + ㄴ/ETM'), ('채', '채/NNB'), ('일그러졌다.', '일그러지/VV + 었/EP + 다/EF + ./SF')]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq-jOBULTY1S",
        "outputId": "182b9711-e007-4eb8-c906-705c4df72609"
      },
      "source": [
        "len(tagged_paragraphs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "561"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAXCSSUsTY1T",
        "outputId": "9360b9c4-11d7-46b4-f59d-5ade8f12a2c7"
      },
      "source": [
        "type(tagged_paragraphs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnLW_Wk8YqzN",
        "outputId": "44123499-d90c-45e5-eea1-86d820b38ada"
      },
      "source": [
        "import pickle\n",
        "answer1 = pickle.load(open('answer1.pkl','rb'))\n",
        "tagged_paragraphs == answer1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDJBY3ynTY1U"
      },
      "source": [
        "##2번: 배점 2점\n",
        "\n",
        "다음을 수행하는 일련의 코드를 제시하시오. \n",
        "1. 문제 1번의 변수 tagged_paragraphs로부터 전체 문단 중 90%(앞부분) 문단을 변수 train으로(training data), 나머지 10%(뒷부분) 문단을 변수 test로(test data) 만들기\n",
        "2. 변수 train(training data)을 이용하여 unigram tagger, bigram tagger, trigram tagger로 구성된 combining tagger 만들고 변수는 combining_tagger로 설정(default tagger는 포함하지 않음)\n",
        "3. 변수 test (test data)을 이용하여 combining tagger 변수 combining_tagger의 정확도를 측정하시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEy-qFwXTY1U"
      },
      "source": [
        "# 2번\n",
        "size = int(len(tagged_paragraphs)*0.9)\n",
        "train_sents = tagged_paragraphs[:size]\n",
        "test_sents = tagged_paragraphs[size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKoO0qR0TY1U"
      },
      "source": [
        "t1 = nltk.UnigramTagger(train_sents)\n",
        "t2 = nltk.BigramTagger(train_sents, backoff = t1)\n",
        "combining_tagger = nltk.TrigramTagger(train_sents, backoff = t2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA7Z02ov5mvt",
        "outputId": "bcd7e6e0-40ec-41fd-fc00-a0ba5a97e082"
      },
      "source": [
        "combining_tagger.evaluate(test_sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6167754897036665"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZhp5MxiTY1U"
      },
      "source": [
        "##3번: 배점 1점\n",
        "\n",
        "문제 2번의 변수 test로부터 어절만 순서대로 추출한 변수 test_words 를 만드시오.(반드시 네모칸에 들어갈 한 줄 코드로 작성하시오)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuF222FCTY1V",
        "outputId": "6160cf6d-97f5-4e85-85d0-5cf3887395e3"
      },
      "source": [
        "# 3번\n",
        "test_words = [j[0] for i in test_sents for j in i]\n",
        "print(test_words[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['내', '계산은', '들어맞았다.', '나는', '우리', '가족들이', '마음으로는', '다들', '원하면서도', '선뜻', '행동으로', '옮기지', '못하고', '있는', '일이', '무엇인지를', '확신했고,', '그', '일을', '할']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3Nou8JkCulM",
        "outputId": "77fa0caf-1934-4fd5-c884-341c267226a5"
      },
      "source": [
        "print(test_words[-20:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['것이', '문학일', '테니까요.', '연재', '기회를', '준', '「작가」와', '이', '불성실한', '작가에게', '지속적인', '애정과', '신뢰를', '보내준', '문학동네에', '고마움을', '전합니다.', '2000년', '가을', '이승우']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xop3p_H9BQEE",
        "outputId": "3c29b077-3370-4a81-dc86-efea1b0322df"
      },
      "source": [
        "len(test_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3982"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAPPf2dwTY1V"
      },
      "source": [
        "## 4번: 배점 2점\n",
        "위쪽 그림으로부터 아래 그림을 도출할 수 있는 함수 defaultNNG 네모칸에 들어갈 한 줄 코드로 작성하시오. <br>\n",
        "(None ⇒ ‘어휘/NNG’)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaaDvIRjTY1V",
        "outputId": "e3802ebd-465d-4e42-91a1-c23bc0759776"
      },
      "source": [
        "# 4번\n",
        "print(combining_tagger.tag(test_words[:10]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('내', '나/NP + 의/JKG'), ('계산은', '계산/NNG + 은/JX'), ('들어맞았다.', None), ('나는', '나/NP + 는/JX'), ('우리', '우리/NP'), ('가족들이', '가족/NNG + 들/XSN + 이/JKS'), ('마음으로는', None), ('다들', None), ('원하면서도', None), ('선뜻', None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvQxbijvTY1W"
      },
      "source": [
        "def defaultNNG(x):\n",
        "    return([(j[0],j[0]+'/NNG') if j[1] is None else j for j in x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG-nrVdNXjPq",
        "outputId": "f21bacbc-f9d7-4e04-834b-b8b1a2589cf0"
      },
      "source": [
        "print(defaultNNG(combining_tagger.tag(test_words[:10])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('내', '나/NP + 의/JKG'), ('계산은', '계산/NNG + 은/JX'), ('들어맞았다.', '들어맞았다./NNG'), ('나는', '나/NP + 는/JX'), ('우리', '우리/NP'), ('가족들이', '가족/NNG + 들/XSN + 이/JKS'), ('마음으로는', '마음으로는/NNG'), ('다들', '다들/NNG'), ('원하면서도', '원하면서도/NNG'), ('선뜻', '선뜻/NNG')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s29KQSlCR218"
      },
      "source": [
        "# 2019년 기말고사\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFRLfMkjCvH4",
        "outputId": "24cf7b94-61dd-45fd-a223-4aed72e6fa6f"
      },
      "source": [
        "#5번\n",
        "import re, os, nltk\n",
        "a = os.listdir('./11_data')\n",
        "a"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hu04.txt',\n",
              " 'hu03.txt',\n",
              " 'na03.txt',\n",
              " 'na01.txt',\n",
              " 'na04.txt',\n",
              " 'na02.txt',\n",
              " 'hu02.txt',\n",
              " 'hu01.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9txOZ5zGDTmR",
        "outputId": "5b180b0f-1585-4045-c0f4-3b593ce4ec86"
      },
      "source": [
        "len(a)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2tVOq53t3_kQ",
        "outputId": "07df7eb3-81fc-42f8-dbd5-91ab1ea4907d"
      },
      "source": [
        "#6번\n",
        "b = [open('./11_data/'+a[7]).read()]\n",
        "b[0][:100]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'So far these remarks, like most criticisms of\\nHardy, have tacitly assumed that his poetry is all of\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d0-BXjHEyDK",
        "outputId": "ca3b2e4d-e1be-4aad-c50e-af2dc8d891e7"
      },
      "source": [
        "#7번\n",
        "c = [w for w in nltk.word_tokenize(b[0])]\n",
        "print(c[:21])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['So', 'far', 'these', 'remarks', ',', 'like', 'most', 'criticisms', 'of', 'Hardy', ',', 'have', 'tacitly', 'assumed', 'that', 'his', 'poetry', 'is', 'all', 'of', 'a']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDIpkmWZ8HuR",
        "outputId": "28bbdbbe-a74b-43ac-f037-df97993b023c"
      },
      "source": [
        "#8번\n",
        "d = nltk.pos_tag(c)\n",
        "print(d[:21])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('So', 'RB'), ('far', 'RB'), ('these', 'DT'), ('remarks', 'NNS'), (',', ','), ('like', 'IN'), ('most', 'JJS'), ('criticisms', 'NNS'), ('of', 'IN'), ('Hardy', 'NNP'), (',', ','), ('have', 'VBP'), ('tacitly', 'RB'), ('assumed', 'VBN'), ('that', 'IN'), ('his', 'PRP$'), ('poetry', 'NN'), ('is', 'VBZ'), ('all', 'DT'), ('of', 'IN'), ('a', 'DT')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChqLB8ocDiIJ",
        "outputId": "5d817fa4-7a5b-4944-91a1-b4a97f23dc0e"
      },
      "source": [
        "#9번\n",
        "e = list(nltk.bigrams(d))\n",
        "e[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('So', 'RB'), ('far', 'RB')),\n",
              " (('far', 'RB'), ('these', 'DT')),\n",
              " (('these', 'DT'), ('remarks', 'NNS')),\n",
              " (('remarks', 'NNS'), (',', ',')),\n",
              " ((',', ','), ('like', 'IN')),\n",
              " (('like', 'IN'), ('most', 'JJS')),\n",
              " (('most', 'JJS'), ('criticisms', 'NNS')),\n",
              " (('criticisms', 'NNS'), ('of', 'IN')),\n",
              " (('of', 'IN'), ('Hardy', 'NNP')),\n",
              " (('Hardy', 'NNP'), (',', ','))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKLGA8ruE-bi",
        "outputId": "fd395ceb-6aca-4bf9-e4ae-ce3823c15cb3"
      },
      "source": [
        "#10번\n",
        "f = nltk.ConditionalFreqDist((b,a[1]) for (a,b) in e)\n",
        "f[('far', 'RB')]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'RB': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WjilpxoFvOr",
        "outputId": "301e1b02-0095-4f36-d153-9b306d291977"
      },
      "source": [
        "#11번\n",
        "g = [(k,v) for k,v in f.items()]\n",
        "g[:5]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('far', 'RB'), FreqDist({'RB': 1})),\n",
              " (('these', 'DT'), FreqDist({'RB': 1})),\n",
              " (('remarks', 'NNS'), FreqDist({'DT': 1})),\n",
              " ((',', ','), FreqDist({'NN': 1, 'NNP': 2, 'NNS': 1})),\n",
              " (('like', 'IN'), FreqDist({',': 1}))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kLfexVB-hhX",
        "outputId": "db7c621a-5786-4f53-d80f-00c4facb7531"
      },
      "source": [
        "#12번\n",
        "h = [(wt, F.max()) for (wt,F) in g]\n",
        "h[:5]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('far', 'RB'), 'RB'),\n",
              " (('these', 'DT'), 'RB'),\n",
              " (('remarks', 'NNS'), 'DT'),\n",
              " ((',', ','), 'NNP'),\n",
              " (('like', 'IN'), ',')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIT0iuTtGTIa",
        "outputId": "14f739fd-7115-438e-ace4-b7d0b5be746f"
      },
      "source": [
        "#13번\n",
        "def y(x):\n",
        "    x = x.lower()\n",
        "    features = {}\n",
        "    for i in 'aeiou':\n",
        "        features[f'count({i})'] = x.count(i)\n",
        "    return features\n",
        "y('seagUll')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'count(a)': 1, 'count(e)': 1, 'count(i)': 0, 'count(o)': 0, 'count(u)': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmpSpMb59fMw",
        "outputId": "eb3421a2-a6f0-4c9b-91f1-b2ce35de0752"
      },
      "source": [
        "labeled_names = [(name, file.replace('.txt', ''))\n",
        "                for file in names.fileids()\n",
        "                for name in names.words(file)]\n",
        "featuresets = [(y(n), gender) for (n,gender) in labeled_names]\n",
        "featuresets[:2]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[({'count(a)': 3, 'count(e)': 1, 'count(i)': 0, 'count(o)': 0, 'count(u)': 0},\n",
              "  'female'),\n",
              " ({'count(a)': 3, 'count(e)': 0, 'count(i)': 1, 'count(o)': 0, 'count(u)': 0},\n",
              "  'female')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tqah1tXaGeNL",
        "outputId": "02194751-8853-4bc2-909a-26882aa0d6ea"
      },
      "source": [
        "#14번\n",
        "z = nltk.NaiveBayesClassifier.train(featuresets)\n",
        "z.classify(y(\"Trinity\"))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'female'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgvJEZN5B8xH"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 기타 이론사항\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vef31meEygKF"
      },
      "source": [
        "## NLTK_ RawText처리\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L8mHf5k0gO1"
      },
      "source": [
        "###ASCII\n",
        "문자 코드: 컴퓨터에서 각 문자를 대응하는 코드 체계\n",
        "\n",
        "미국 정보교환 표준부호, 영문 알파벳 문자 인코딩, 8bit 이진수 연쇄를 통한 알파벳, 문장부호, 제어문자 부호화\n",
        "\n",
        "###한글 코드\n",
        "조합형 코드\n",
        "* 16bit = MSB + 초(5) + 중(5) + 종(5)\n",
        "* 음절 모두 표현 가능\n",
        "\n",
        "완성형 코드\n",
        "* 16bit, 미리 정의된 문자 이외는 사용 불가능\n",
        "* EUC-KR (기본 완성형) ~ 20%만 사용\n",
        "* cp949 (확장 완성형)\n",
        "\n",
        "###Unicode\n",
        "전세계 문자를 하나의 코드 체계로 표준화한 문자코드세트 (한자, 한글, ASCII, 기호 등등) ex) UTF-8\n",
        "* EUC-KR의 경우 코드번호순서와 사전 정렬순서 일치, cp949는 아님\n",
        "* unicode는 한글 음절문자 11,172개를 사전정렬순에 의해 코드번호 부여\n",
        "\n",
        "###Tokenization\n",
        "\n",
        "어휘 단위 분리, 소문자변환, 소유격 제거, 문장부호/숫자 분리/제거 등\n",
        "* 대문자가 필요할 때\n",
        "* 특수문자가 사용된 단어\n",
        "\n",
        "###분포 가설\n",
        "\n",
        "같은 contexts 내에서 발생하고 사용되어지는 단어들은 같은 의미를 말하고 있는 경향이 있다. \n",
        "\n",
        "전산언어학, 인지과학 등에서 어휘 의미를 접근하는 토대\n",
        "\n",
        "###연어(collocation)\n",
        "\n",
        "동일 문장, 동일 맥락에서 빈번하게 함께 사용되는 어휘쌍\n",
        "\n",
        "두 어휘의 습득은 대부분 함께 습득\n",
        "* 특정 맥락, 주제와 관련\n",
        "* 문화적 맥락과 관련 \n",
        "* 머릿속 사전에서 연관\n",
        "\n",
        "친숙성/빈도 효과, 촉발효과와 관련 있다. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlIaxeNNC-Fn"
      },
      "source": [
        "## NLTK_영어어휘품사분석\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMErVVEBDIx4"
      },
      "source": [
        "###**자연어 처리의 어휘처리의 중요성**\n",
        "* 어휘: 기본적 의미 단위\n",
        "* 어휘는 형식적 식별의 용이성 보유\n",
        "\n",
        "####형태소\n",
        "* 형태소: 의미의 최소 단위 ex) prefix, suffix\n",
        "* 독립 형태소/의존 형태소 etc.\n",
        "\n",
        "####어근, 어간\n",
        "* 어휘 = 어근 + 접사 ex) **paint**er, con**cieve**\n",
        "* 어간 = 굴절 접사 등등\n",
        "\n",
        "####파생 형태소\n",
        "* 굴절 형태소: 품사 변화 X\n",
        "* but 파생 형태소: 품사 변화 O (pure -> pur**ify**)\n",
        "\n",
        "####내용어와 기능어\n",
        "* 내용어: 의미 내용을 가짐 (ex: n. v. open class)\n",
        "* 기능어: 문법 기능 (conj. prep. pron. closed class)\n",
        "* 문법 형태소: 양화, 형식, 시제 등등...\n",
        "</br></br>\n",
        "* nltk Text에서 findall 기능을 적용 가능\n",
        "* string: findall 기능 적용 불가능 (re.findall 사용)\n",
        "* 그러나 <.*> 각괄호 사용 불가\n",
        "\n",
        "###**Tokenization의 필요성**\n",
        "* 문자변환, 문장부호, 숫자제거 등등...\n",
        "* 형태론적 표준화 (stemming/lemmatization) 역시 포함\n",
        "* **nltk.word_tokenize(text)**\n",
        "\n",
        "####Stemming\n",
        "* 굴절접사의 제거 (ex: cars->car, but supplies->supplie)\n",
        "* nltk.PorterStemmer() / LancasterStemmer()\n",
        "\n",
        "####Lemmatization\n",
        "* 어간의 사전 표제형 (lemma) 추출 - 형태소분석 要\n",
        "* nltk.WordNetLemmatizer()\n",
        "\n",
        "####굴절어와 교착어\n",
        "* 굴절어: 품사분석, PoS (형태론적 복잡성 낮음) ex) 영어\n",
        "* 교착어: morphological tag ex) 한국어\n",
        "\n",
        "###**영어 POS**\n",
        "* 형태적, 통사적 기능에 근거한 정의\n",
        "* close class / open class\n",
        "\n",
        "####bi-gram\n",
        "* list(nltk.bigrams(words))\n",
        "\n",
        "###**tagger**\n",
        "* 빈도와 중의성: can (cans/canned/can't)\n",
        "* rule-based(regex), stochastic, hybird\n",
        "* tagger 함수: **nltk.pos_tag(text)**, nltk.DefaultTagger('NN'), nltk.RegexpTagger(patterns)\n",
        "* pickle 등으로 저장 및 불러오기 가능.\n",
        "\n",
        "####Unigram Tagger\n",
        "* 모든 어휘 목록에서 높은 확률, 자체 training\n",
        "* Trigram으로 갈수록 중의성 제거 확률 높아짐.\n",
        "\n",
        "####Combining tagger\n",
        "* Trigram have ```None?``` -> bi -> uni -> default..\n",
        "* tagger에 따라 정확도 떨어질 수 있음, 저빈도 cutoff\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x1vMAeA8v0N"
      },
      "source": [
        "## NLTK_분류\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxUNbh1zCThk"
      },
      "source": [
        "###**기계학습의 종류**\n",
        "* **Supervised ML**\n",
        "* training data의 입출력쌍 학습\n",
        "* 분류 회귀모형 (현 nltk 모델)\n",
        "\n",
        "\n",
        "* **Unsupervised ML**\n",
        "* 입력만 있고 출력은 없는 경우, 패턴 탐색\n",
        "* Clustering, Association\n",
        "\n",
        "####Supervised ML 과정\n",
        "* 입출력쌍 mapping (feature extract) - 학습\n",
        "* label(정답) - classifier model 예측\n",
        "\n",
        "어떤 모형을 선택하고 적절한 Feature를 추출하는 것이 중요하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR2wYkafByXd"
      },
      "source": [
        "#연습문제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoH9DW3FCjyM"
      },
      "source": [
        "## NLTK_영어어휘품사분석\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azPCYB9aJCx3"
      },
      "source": [
        "영어어휘품사분석I (연습문제 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx73dSCFCnvJ"
      },
      "source": [
        "def stem1(word):\n",
        "    for suffix in ['ing', 'ed','s']:\n",
        "        if word.endswith(suffix):\n",
        "            return(word[:-len(suffix)])\n",
        "    return word"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBlKscjdJCCn"
      },
      "source": [
        "def stem2(word):\n",
        "    return re.sub('(ing|ed|s)$','',word)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM6HySn0MENo"
      },
      "source": [
        "영어어휘품사분석III (연습문제 1, 2)\n",
        "\n",
        "해당 Chapter에서 tabulate, ConditionalFreqDist, [링크 텍스트](https://)n-gram 활용 관련 예제 참조"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSMn72awJTxn",
        "outputId": "8c7dab89-15a2-43f2-875a-e137801237e2"
      },
      "source": [
        "words = nltk.corpus.brown.tagged_words(categories='news', tagset='universal')\n",
        "words[:5]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DET'),\n",
              " ('Fulton', 'NOUN'),\n",
              " ('County', 'NOUN'),\n",
              " ('Grand', 'ADJ'),\n",
              " ('Jury', 'NOUN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2Kb6WTkYRZf",
        "outputId": "9fea0ea0-001f-479e-bef5-bc433f720628"
      },
      "source": [
        "verbs = [x[0] for x in nltk.FreqDist(w for w,t in words if t == 'VERB').most_common()][:10]\n",
        "print(verbs)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['is', 'was', 'be', 'said', 'will', 'are', 'has', 'had', 'have', 'were']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlyIDVN1Yjnb",
        "outputId": "989f74b4-5622-48f5-f588-85fb6b00b810"
      },
      "source": [
        "noun_modifiers = [x[1] for x,b in nltk.bigrams(words) if b[1] == 'NOUN']\n",
        "noun_modifiers = [tag for (tag,_) in nltk.FreqDist(noun_modifiers).most_common()]\n",
        "print(noun_modifiers)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NOUN', 'DET', 'ADJ', 'ADP', '.', 'VERB', 'CONJ', 'NUM', 'ADV', 'PRT', 'PRON', 'X']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUDHQhrOdnud",
        "outputId": "d8f76242-0092-422f-ab79-0879760cead1"
      },
      "source": [
        "cfd1 = nltk.ConditionalFreqDist(words)\n",
        "cfd1['yield'].most_common() #dictionary임"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('NOUN', 5), ('VERB', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSjiznnd5DyV"
      },
      "source": [
        "영어어휘품사분석IV, V (Practice)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMnQn-xjdwgv",
        "outputId": "e12bc6f9-0e6e-4c21-838b-9b2959714720"
      },
      "source": [
        "fd = nltk.FreqDist(brown.words(categories='news'))\n",
        "cfd = nltk.ConditionalFreqDist(brown.tagged_words(categories='news'))\n",
        "cfd['the']"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'AT': 5558, 'AT-HL': 4, 'AT-TL': 18})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPUPTZlJw6rH"
      },
      "source": [
        "likely_tags = dict((word, cfd[word].max())\n",
        "        for (word,_) in fd.most_common(50))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7adTB3WcdyZ"
      },
      "source": [
        "tagged_sents = list(brown.tagged_sents(categories='news'))\n",
        "random.shuffle(tagged_sents)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRaAO-uXxExd"
      },
      "source": [
        "precision = [nltk.UnigramTagger(model=dict((word, cfd[word].max()) \n",
        "            for (word, _) in fd.most_common(i))).evaluate(tagged_sents) \n",
        "            for i in range(100, len(fd.most_common()), 100)] #고빈도 어휘를 얼마만큼 사용하는지?"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRSeWViu5J3E"
      },
      "source": [
        "KoNLPy (연습문제 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1HpcFiQzUWW",
        "outputId": "66a57613-e967-4e55-8e18-3743e3862594"
      },
      "source": [
        "from konlpy.tag import Kkma\n",
        "kkma = Kkma()\n",
        "a = os.getcwd()\n",
        "b = os.listdir('./15_data')\n",
        "tagged = [j for i in b \n",
        "          for j in kkma.pos(open('/'.join([a, '15_data', i]), encoding='utf8').read())]\n",
        "len(tagged)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "429"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-_MxASR5q-P",
        "outputId": "e77ef5c5-5f34-494f-bf19-2f9b8ae985ce"
      },
      "source": [
        "print(tagged[:10])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('북미', 'NNG'), ('양국', 'NNG'), ('이', 'JKS'), ('3', 'NR'), ('일', 'NNM'), ('오후', 'NNG'), ('판문점', 'NNG'), ('에서', 'JKM'), ('12', 'NR'), ('일', 'NNM')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHB-vasl6v5T"
      },
      "source": [
        "한글자소처리 (연습문제 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7TGitrrWG4T",
        "outputId": "dc6051dd-f3f6-458e-b583-72a46cd8996e"
      },
      "source": [
        "ord('힣')-ord('가')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11171"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0uZWgMgW5pc",
        "outputId": "9800e1ce-4f5b-4986-d2f5-5d96fadcb492"
      },
      "source": [
        "[chr(i) for i in range(44032, 44042)]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['가', '각', '갂', '갃', '간', '갅', '갆', '갇', '갈', '갉']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W1FCSKHYEft"
      },
      "source": [
        "def test1(a, b):\n",
        "    suffix = jaso1(b)[0]\n",
        "    stem = jaso1(a[-1])[-1]\n",
        "    if stem != '':\n",
        "        if suffix == 'ㅇ':\n",
        "            return '결합가능'\n",
        "        else:\n",
        "            return '결합불가'\n",
        "    else:\n",
        "        if suffix != 'ㅇ':\n",
        "            return '결합가능'\n",
        "        else:\n",
        "            return '결합불가'\n",
        "test1('사과','이')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqQ11FRq8TLe"
      },
      "source": [
        "def test2(x):\n",
        "    import re\n",
        "    final = jaso2(x[-1])\n",
        "    if re.search('ㄴ$|ㄹ$',final[-1]):\n",
        "        stemming = final[:-1]+['']\n",
        "        return(x[:-1] + jaso1(*stemming))\n",
        "    else:\n",
        "        return(x)\n",
        "test2(\"사관\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRCUSc4oCTh-"
      },
      "source": [
        "## NLTK_분류\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCV5j_G7CTh_"
      },
      "source": [
        "labeled_names = [(name, file.replace('.txt', ''))\n",
        "                for file in names.fileids()\n",
        "                for name in names.words(file)]\n",
        "random.shuffle(labeled_names)"
      ],
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHGIJYe0CTh_",
        "outputId": "79f11fb0-3993-4f3a-b348-64a956e80743"
      },
      "source": [
        "features = [({'last_letter': name[-1]}, gender) for (name,gender) in labeled_names]\n",
        "train_set, test_set = features[:500], features[:500]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "nltk.classify.accuracy(classifier, test_set)"
      ],
      "execution_count": 378,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.794"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 378
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4WkraelCTiA",
        "outputId": "53c9902b-3b99-4619-b4d3-8fb101d415fa"
      },
      "source": [
        "classifier.show_most_informative_features()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "             last_letter = 'a'            female : male   =     14.8 : 1.0\n",
            "             last_letter = 'r'              male : female =      8.7 : 1.0\n",
            "             last_letter = 'o'              male : female =      8.0 : 1.0\n",
            "             last_letter = 't'              male : female =      7.0 : 1.0\n",
            "             last_letter = 'm'              male : female =      6.7 : 1.0\n",
            "             last_letter = 'd'              male : female =      5.9 : 1.0\n",
            "             last_letter = 's'              male : female =      3.8 : 1.0\n",
            "             last_letter = 'g'              male : female =      3.1 : 1.0\n",
            "             last_letter = 'h'              male : female =      2.4 : 1.0\n",
            "             last_letter = 'e'            female : male   =      2.2 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fdYVXIjcCTiA",
        "outputId": "4924c95e-ee21-4e94-a1c9-901466954755"
      },
      "source": [
        "classifier.classify({'last_letter': 'e'})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'female'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f75swI7UCTiA"
      },
      "source": [
        "**분류 I** (연습문제 1, 2 ,3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMQMJK2YCTiB",
        "outputId": "b04cb5fe-42f8-47de-bd6a-cbbd96a6c6f6"
      },
      "source": [
        "labeled_names = [(name, file.replace('.txt', ''))\n",
        "                for file in names.fileids()\n",
        "                for name in names.words(file)]\n",
        "random.shuffle(labeled_names)\n",
        "len(labeled_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNWPk46MCTiB",
        "outputId": "6fa374f8-fe3d-4549-96ed-be5c6b0906b8"
      },
      "source": [
        "labeled_names[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Hussein', 'male'),\n",
              " ('Ruddie', 'male'),\n",
              " ('Edita', 'female'),\n",
              " ('Deonne', 'female'),\n",
              " ('Jill', 'female'),\n",
              " ('Oliver', 'male'),\n",
              " ('Theodosia', 'female'),\n",
              " ('Cris', 'male'),\n",
              " ('Silvan', 'male'),\n",
              " ('Rustie', 'male')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6nnDygZCTiB",
        "outputId": "081dfc2f-99a9-4386-9949-354b03ca3ac8"
      },
      "source": [
        "features = [({'first_letter': name[0].lower()}, {'last_letter': name[-1]}, {'name_length': len(name)}, gender) for (name,gender) in labeled_names]\n",
        "features[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[({'first_letter': 'h'}, {'last_letter': 'n'}, {'name_length': 7}, 'male'),\n",
              " ({'first_letter': 'r'}, {'last_letter': 'e'}, {'name_length': 6}, 'male'),\n",
              " ({'first_letter': 'e'}, {'last_letter': 'a'}, {'name_length': 5}, 'female'),\n",
              " ({'first_letter': 'd'}, {'last_letter': 'e'}, {'name_length': 6}, 'female'),\n",
              " ({'first_letter': 'j'}, {'last_letter': 'l'}, {'name_length': 4}, 'female')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrBMXgRhCTiB"
      },
      "source": [
        "size = int(len(features) *0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0geQ3NJCTiB"
      },
      "source": [
        "def gender_features1(name):\n",
        "    features = {}\n",
        "    features['name_length'] = len(name)\n",
        "    features[\"first_letter\"] = name[0].lower()\n",
        "    features[\"last_letter\"] = name[-1].lower()\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MhS9rRNCTiC"
      },
      "source": [
        "features = [(gender_features1(name), gender) for name, gender in labeled_names]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2hxW09PCTiC",
        "outputId": "e2c9ae9e-d3ac-4678-ccaa-ba795157b8ec"
      },
      "source": [
        "size = int(len(features) *0.9)\n",
        "train_set, test_set = features[:size], features[size:]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "nltk.classify.accuracy(classifier, test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.759748427672956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tsyV5fdCTiC",
        "outputId": "e232dfb5-382a-4cad-86ff-36a37bf949ec"
      },
      "source": [
        "classifier.show_most_informative_features(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "             last_letter = 'a'            female : male   =     35.8 : 1.0\n",
            "             last_letter = 'k'              male : female =     31.3 : 1.0\n",
            "             last_letter = 'v'              male : female =     16.4 : 1.0\n",
            "             last_letter = 'f'              male : female =     15.3 : 1.0\n",
            "             last_letter = 'd'              male : female =     12.3 : 1.0\n",
            "             last_letter = 'p'              male : female =     11.2 : 1.0\n",
            "             last_letter = 'm'              male : female =      8.9 : 1.0\n",
            "             last_letter = 'o'              male : female =      8.0 : 1.0\n",
            "             last_letter = 'r'              male : female =      6.6 : 1.0\n",
            "             last_letter = 'w'              male : female =      5.4 : 1.0\n",
            "             last_letter = 'g'              male : female =      4.9 : 1.0\n",
            "            first_letter = 'w'              male : female =      4.5 : 1.0\n",
            "             last_letter = 't'              male : female =      4.5 : 1.0\n",
            "             last_letter = 's'              male : female =      4.2 : 1.0\n",
            "             last_letter = 'b'              male : female =      4.1 : 1.0\n",
            "             last_letter = 'z'              male : female =      4.0 : 1.0\n",
            "             last_letter = 'j'              male : female =      4.0 : 1.0\n",
            "             last_letter = 'i'            female : male   =      3.5 : 1.0\n",
            "             name_length = 2                male : female =      3.0 : 1.0\n",
            "            first_letter = 'u'              male : female =      2.9 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CbpJKd6fCTiC",
        "outputId": "15056f82-9b5f-4b54-c838-31b3ab9f9c90"
      },
      "source": [
        "classifier.classify(gender_features1('John'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'male'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNi-nkAB-pz_"
      },
      "source": [
        "**분류 II** (연습문제 1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AN6Pjmj_wRd"
      },
      "source": [
        "train_names = labeled_names[1500:]\n",
        "devtest_names = labeled_names[500:1500]\n",
        "test_names = labeled_names[:500]"
      ],
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hQXUCLGCTiE"
      },
      "source": [
        "def gender_features_ex(name):\n",
        "    features = {}\n",
        "    features[\"last_two_letters\"] = name[-2:].lower()\n",
        "    features[\"last_letter\"] = name[-1:].lower()\n",
        "    return features "
      ],
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lnmZjb8CTiF",
        "outputId": "44927c05-a1c0-48ed-9431-93b67b5c9f45"
      },
      "source": [
        "train_set = [(gender_features_ex(n), gender) for (n, gender) in train_names]\n",
        "devtest_set = [(gender_features_ex(n), gender) for (n, gender) in devtest_names]\n",
        "test_set = [(gender_features_ex(n), gender) for (n, gender) in test_names]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "nltk.classify.accuracy(classifier, devtest_set)"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.79"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fQSKN2RCTiF",
        "outputId": "4f68f14c-d06f-4341-b6c0-e0bd63343244"
      },
      "source": [
        "nltk.classify.accuracy(classifier, test_set)"
      ],
      "execution_count": 386,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.802"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 386
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fod_bYCN_GR6",
        "outputId": "beae31e1-2a94-4012-ba15-427707374505"
      },
      "source": [
        "def gender_features(word):\n",
        "    return {'suffix1': word[-1], 'suffix2':word[-2]}\n",
        "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
        "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
        "test_set = [(gender_features(n), gender) for (n, gender) in test_names]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "nltk.classify.accuracy(classifier, devtest_set)"
      ],
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.762"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA3JRo5s_dpT",
        "outputId": "a1865281-cc8d-4038-911b-68bc3bf96847"
      },
      "source": [
        "nltk.classify.accuracy(classifier, test_set)"
      ],
      "execution_count": 390,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.774"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 390
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2g-v4WhCTiF"
      },
      "source": [
        "NLTK_분류 III (연습문제 1, 2, 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTNy42N-CTiH"
      },
      "source": [
        "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
        "word_features = list(all_words)[:1000] #일반적인 형태를 feature extraction하기 쉬움"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfWekzlbCTiH"
      },
      "source": [
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features[f'contains({word})'] = word in document_words\n",
        "    return features "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCjHkHNuCTiH"
      },
      "source": [
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbKFgcf1CTiH",
        "outputId": "bdb18fe1-89e7-4a72-ac9c-d79b804f951c"
      },
      "source": [
        "nltk.classify.accuracy(classifier,test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.76"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_8eSNAJCTiH",
        "outputId": "3644b90d-a4e0-4b9f-8544-1f0e69ed7d97"
      },
      "source": [
        "classifier.show_most_informative_features(5) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "        contains(turkey) = True              neg : pos    =      6.7 : 1.0\n",
            "        contains(wasted) = True              neg : pos    =      5.4 : 1.0\n",
            "         contains(awful) = True              neg : pos    =      5.3 : 1.0\n",
            "       contains(unravel) = True              pos : neg    =      5.1 : 1.0\n",
            "     contains(stretched) = True              neg : pos    =      4.1 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I7PYb9GCTiI"
      },
      "source": [
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    word_features = ['stretched', 'turkey', 'singers','unravel', 'awful', 'wasted']\n",
        "    for word in word_features:\n",
        "        features[f'contains({word})'] = word in document_words\n",
        "    return features "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhHm5UzTCTiI",
        "outputId": "e63bc4b5-5a4f-431e-8048-a22f72457b01"
      },
      "source": [
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "nltk.classify.accuracy(classifier,test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.59"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCarB62TCTiI"
      },
      "source": [
        "def document_features(document):\n",
        "    import re\n",
        "    letters = ''.join(document)\n",
        "    features = {\n",
        "        'ratio_alphabet': len(re.findall('[a-z]', letters, re.I))/len(letters),\n",
        "        'ratio_digit': len(re.findall('\\d', letters))/len(letters),\n",
        "        'ratio_punct': len(re.findall('[^\\w]', letters))/len(letters)\n",
        "    }\n",
        "    return features "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uchMx_IaCTiI",
        "outputId": "4c01af25-492d-43fb-b993-73a7c8b6b108"
      },
      "source": [
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "nltk.classify.accuracy(classifier,test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.59"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9tTBvh0CTiI",
        "outputId": "cd814a29-7751-4da1-e323-484ca51b9c54"
      },
      "source": [
        "classifier.show_most_informative_features(5) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "             ratio_digit = 0.0026666666666666666    pos : neg    =      1.7 : 1.0\n",
            "          ratio_alphabet = 0.9523809523809523    neg : pos    =      1.7 : 1.0\n",
            "          ratio_alphabet = 0.9583333333333334    neg : pos    =      1.7 : 1.0\n",
            "             ratio_punct = 0.03959731543624161    neg : pos    =      1.7 : 1.0\n",
            "             ratio_digit = 0.0032502708559046588    neg : pos    =      1.7 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVSZPZ1VCTiJ"
      },
      "source": [
        "NLTK_분류 IV (연습문제 1, 2, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzfzIPFFCTiI",
        "outputId": "53c41f39-2f5b-4392-8076-04ba5a627419"
      },
      "source": [
        "suffix_fdist = nltk.FreqDist()\n",
        "for word in brown.words():\n",
        "    word = word.lower()\n",
        "    suffix_fdist[word[-1:]] += 1 #Unigram 빈도\n",
        "    suffix_fdist[word[-2:]] += 1 #Bigram 빈도\n",
        "    suffix_fdist[word[-3:]] += 1 #Trigram 빈도\n",
        "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\n",
        "common_suffixes[:10]\n",
        "#문자길이 1, 2 등일 경우 중복 count가 될 때 정확도가 낮아질 수 있다. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IBHkJ9UCTiJ",
        "outputId": "a0883855-1723-4cf2-ede9-00022a940600"
      },
      "source": [
        "suffix_fdist = nltk.FreqDist()\n",
        "for word in ['','a','ab','abc']:\n",
        "    word = word.lower()\n",
        "    if len(word) != 0:\n",
        "        suffix_fdist[word[-1:]] += 1\n",
        "    if len(word) > 1:\n",
        "        suffix_fdist[word[-2:]] += 1 \n",
        "    if len(word) > 2:\n",
        "        suffix_fdist[word[-3:]] += 1   \n",
        "suffix_fdist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'a': 1, 'ab': 1, 'abc': 1, 'b': 1, 'bc': 1, 'c': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFrTqrA-CTiK",
        "outputId": "38628ce2-0cb4-42ea-842e-d1fa9646b7e1"
      },
      "source": [
        "errors_Naive =[]\n",
        "for (word,tag) in tagged_words[-1000:]:\n",
        "    guess = classifier.classify(pos_features(word))\n",
        "    guess1 = classifier1.classify(pos_features(word))\n",
        "    if guess != tag and guess1 == tag: \n",
        "        errors_Naive.append((word,tag,guess,guess1))\n",
        "errors_Naive[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('5', 'CD', 'NN', 'CD'),\n",
              " ('business', 'NN', 'NP', 'NN'),\n",
              " ('as', 'CS', 'HVZ', 'CS'),\n",
              " ('a', 'AT', 'NP', 'AT'),\n",
              " ('a', 'AT', 'NP', 'AT'),\n",
              " ('a', 'AT', 'NP', 'AT'),\n",
              " ('1960', 'CD', 'NN', 'CD'),\n",
              " ('at', 'IN', 'CS', 'IN'),\n",
              " ('he', 'PPS', 'AT', 'PPS'),\n",
              " ('he', 'PPS', 'AT', 'PPS')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63ts1_gtCTiK",
        "outputId": "8712a9d7-6ad8-4120-8694-0b0407d41cc8"
      },
      "source": [
        "errors_Decision =[]\n",
        "for (word,tag) in tagged_words[-1000:]:\n",
        "    guess = classifier.classify(pos_features(word))\n",
        "    guess1 = classifier1.classify(pos_features(word))\n",
        "    if guess == tag and guess1 != tag: \n",
        "        errors_Decision.append((word,tag,guess,guess1))\n",
        "errors_Decision[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('milk', 'NN', 'NN', 'CD'),\n",
              " ('were', 'BED', 'BED', 'CD'),\n",
              " ('task', 'NN', 'NN', 'CD'),\n",
              " ('all', 'ABN', 'ABN', 'CD'),\n",
              " ('government', 'NN', 'NN', 'CD'),\n",
              " ('birdie', 'NN', 'NN', 'CD'),\n",
              " ('ceramic', 'JJ', 'JJ', 'CD'),\n",
              " ('not', '*', '*', 'CD'),\n",
              " ('place', 'NN', 'NN', 'CD'),\n",
              " ('work', 'NN', 'NN', 'CD')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-rxdT-PCTiM"
      },
      "source": [
        "## NLTK_감성분석\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEIs5tiQCTiO"
      },
      "source": [
        "Movie Review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzQIEFgHCTiO",
        "outputId": "90a251fb-1f58-4c7d-ea75-9d7970f029bb"
      },
      "source": [
        "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
        "word_features = list(all_words)[:1000]\n",
        "print(word_features[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an', 'accident', 'one', 'of', 'the', 'guys', 'dies', 'but', 'his', 'girlfriend', 'continues', 'see', 'him', 'in', 'her', 'life', 'has', 'nightmares', 'what', \"'\", 's', 'deal', '?', 'watch', 'movie', '\"', 'sorta', 'find', 'out', 'critique', 'mind', '-', 'fuck', 'for', 'generation', 'that', 'touches', 'on', 'very', 'cool', 'idea', 'presents', 'it', 'bad', 'package', 'which', 'is', 'makes', 'this', 'review', 'even', 'harder', 'write', 'since', 'i', 'generally', 'applaud', 'films', 'attempt', 'break', 'mold', 'mess', 'with', 'your', 'head', 'such', '(', 'lost', 'highway', '&', 'memento', ')', 'there', 'are', 'good', 'ways', 'making', 'all', 'types', 'these', 'folks']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlYMiwq9CTiP",
        "outputId": "b2a6ed6c-e15a-424e-fffb-4281e395fb15"
      },
      "source": [
        "print(nltk.corpus.stopwords.words('english'[:50]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8qKXDKvCTiP",
        "outputId": "c5190322-8cf4-460b-ead4-cd9133cc8b3d"
      },
      "source": [
        "len(word_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbqz9oIPCTiP",
        "outputId": "537bbe38-b07d-4485-eac3-b235b76e6e77"
      },
      "source": [
        "word_ranking = set(word_features) - set(nltk.corpus.stopwords.words('english'))\n",
        "len(word_ranking)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "885"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg2UtFavCTiP",
        "outputId": "9facd48f-bb57-4654-eea4-a82bac2c60c4"
      },
      "source": [
        "word_ranking = sorted(word_ranking)\n",
        "print(word_ranking[:40])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['!', '\"', '&', \"'\", '(', ')', ',', '-', \"-'\", '--', '.', '/', '10', '1960', '1990s', '1997', '2', '20', '20th', '3', '4', '7', '8', '9', '90s', ':', ';', '?', 'able', 'abo', 'accident', 'accidentally', 'across', 'acting', 'action', 'actor', 'actors', 'actually', 'adequate', 'ads']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMwspbzuCTiP",
        "outputId": "b37c39d7-c6c0-4c63-be0d-1dd4d1cf4a0d"
      },
      "source": [
        "import re\n",
        "word_ranking = [i for i in word_ranking if re.search('[a-z]', i)]\n",
        "len(word_ranking)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "860"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzv4DplWCTiP"
      },
      "source": [
        "documents = [(list(movie_reviews.words(fileid)), category) \n",
        "            for category in movie_reviews.categories() \n",
        "            for fileid in movie_reviews.fileids(category)]\n",
        "random.shuffle(documents)\n",
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features[f'contains({word})'] = word in document_words\n",
        "    return features "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFE_C6D5CTiP",
        "outputId": "66cb07e9-b786-42d9-91d1-df14411c6081"
      },
      "source": [
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "nltk.classify.accuracy(classifier, test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.77"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDa92QEECTiQ",
        "outputId": "f95847da-ca17-4163-9cea-a6c676a786ea"
      },
      "source": [
        "classifier.show_most_informative_features(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "        contains(turkey) = True              neg : pos    =      6.6 : 1.0\n",
            "       contains(singers) = True              pos : neg    =      6.3 : 1.0\n",
            "         contains(kudos) = True              pos : neg    =      5.8 : 1.0\n",
            "     contains(underwood) = True              neg : pos    =      5.7 : 1.0\n",
            "        contains(wasted) = True              neg : pos    =      5.3 : 1.0\n",
            "        contains(poorly) = True              neg : pos    =      5.3 : 1.0\n",
            "         contains(awful) = True              neg : pos    =      5.1 : 1.0\n",
            "       contains(bronson) = True              neg : pos    =      5.0 : 1.0\n",
            "       contains(unravel) = True              pos : neg    =      5.0 : 1.0\n",
            "        contains(sexist) = True              neg : pos    =      4.6 : 1.0\n",
            "       contains(runtime) = True              neg : pos    =      4.4 : 1.0\n",
            "     contains(stretched) = True              neg : pos    =      4.2 : 1.0\n",
            "          contains(dull) = True              neg : pos    =      4.0 : 1.0\n",
            "         contains(bland) = True              neg : pos    =      3.9 : 1.0\n",
            "       contains(jumbled) = True              neg : pos    =      3.8 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhi1Fba4CTiQ"
      },
      "source": [
        "negative = movie_reviews.words(categories='neg')\n",
        "positive = movie_reviews.words(categories='pos')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcAU79F3CTiQ",
        "outputId": "67a32849-d877-4ec9-ad8a-134cbc5844a4"
      },
      "source": [
        "A = {word for word,_ in nltk.FreqDist(w.lower() for w in negative).most_common(1000)}\n",
        "B = {word for word,_ in nltk.FreqDist(w.lower() for w in positive).most_common(1000)}\n",
        "XOR = A^B \n",
        "len(XOR) #매우 줄어듬-Stopword 방식 이외에도 사용 방법에 따라 이득을 볼 수 있음"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "302"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE5alKFsCTiQ",
        "outputId": "966b4350-3ce0-40c7-f25c-2470c28ddcb9"
      },
      "source": [
        "XOR = sorted(XOR)\n",
        "print(XOR[:80])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['+', '4', '5', '8', '90', 'above', 'add', 'air', 'allen', 'amazing', 'amusing', 'animated', 'animation', 'annoying', 'anyway', 'appear', 'approach', 'army', 'arnold', 'ask', 'aspect', 'ass', 'atmosphere', 'audiences', 'awful', 'b', 'batman', 'beauty', 'believable', 'biggest', 'bland', 'bond', 'boring', 'brilliant', 'british', 'brought', 'brown', 'budget', 'bunch', 'cage', 'cameron', 'cannot', 'carter', 'catch', 'chan', 'chase', 'cheap', 'chemistry', 'choice', 'christopher', 'cinematography', 'class', 'clearly', 'club', 'cold', 'college', 'complex', 'constantly', 'control', 'convincing', 'couldn', 'crap', 'created', 'credit', 'culture', 'decent', 'definitely', 'delivers', 'depth', 'deserves', 'details', 'development', 'disaster', 'doctor', 'double', 'dream', 'dreams', 'dull', 'dumb', 'earlier']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc8gWgDYCTiQ"
      },
      "source": [
        "positive_words = B-A\n",
        "negative_words = A-B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbRx-kzZCTiQ",
        "outputId": "1dd7c44e-c8b2-4924-a3ef-33534610a38f"
      },
      "source": [
        "print(sorted(positive_words)[:40])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['+', '8', 'above', 'allen', 'amazing', 'animated', 'animation', 'approach', 'army', 'aspect', 'atmosphere', 'audiences', 'beauty', 'believable', 'bond', 'brilliant', 'british', 'brought', 'brown', 'cameron', 'cannot', 'carter', 'chan', 'chemistry', 'choice', 'cinematography', 'class', 'clearly', 'cold', 'complex', 'constantly', 'convincing', 'created', 'credit', 'culture', 'definitely', 'delivers', 'depth', 'deserves', 'details']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjxOeV2nCTiR",
        "outputId": "289bdc88-f419-4cb7-e9e8-76bafd5f2dc5"
      },
      "source": [
        "print(sorted(negative_words)[:40])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['4', '5', '90', 'add', 'air', 'amusing', 'annoying', 'anyway', 'appear', 'arnold', 'ask', 'ass', 'awful', 'b', 'batman', 'biggest', 'bland', 'boring', 'budget', 'bunch', 'cage', 'catch', 'chase', 'cheap', 'christopher', 'club', 'college', 'control', 'couldn', 'crap', 'decent', 'development', 'disaster', 'doctor', 'double', 'dull', 'dumb', 'eddie', 'effort', 'entirely']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvrlS-AKCTiR"
      },
      "source": [
        "def value_of (word):\n",
        "    if word in positive_words:\n",
        "        return 1\n",
        "    elif word in negative_words:\n",
        "        return -1\n",
        "    return 0\n",
        "def sentiment_score(document):\n",
        "    return(sum(value_of(word) for word in document))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAQo8u6gCTiR",
        "outputId": "8564df3e-c847-46a6-dccd-f9ace361e5f5"
      },
      "source": [
        "sentiment_score(movie_reviews.words(\n",
        "    random.sample(\n",
        "        movie_reviews.fileids(categories='neg'), 1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRzWxLO9CTiR",
        "outputId": "67d94364-d795-418f-9d8b-fd160ffcd908"
      },
      "source": [
        "sum(sentiment_score(movie_reviews.words(fileid)) \n",
        "    for fileid in movie_reviews.fileids(categories='neg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-6449"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyzKO-Q4CTiR"
      },
      "source": [
        "VADER Sentiment Analysis Tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9-PGk7sCTiR",
        "outputId": "98f80541-d097-402d-d453-127afb06c613"
      },
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6DQlzRcCTiR",
        "outputId": "af900ada-c0b7-4f2d-e0b3-c5cad59ae13e"
      },
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "sia.polarity_scores(\"Wow, NLTK is really powerful!!\") #dict type"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.8165, 'neg': 0.0, 'neu': 0.286, 'pos': 0.714}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vpI7gzZCTiR",
        "outputId": "96d20012-2077-4e22-c7ed-e3bc1ff914c3"
      },
      "source": [
        "sia.polarity_scores(movie_reviews.raw(random.sample(movie_reviews.fileids(categories='pos'), 1))) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.8585, 'neg': 0.065, 'neu': 0.829, 'pos': 0.107}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXy9fU9mCTiS",
        "outputId": "81a0ec88-b727-4196-ed30-7a50db2728a8"
      },
      "source": [
        "sum(sia.polarity_scores(movie_reviews.raw(fileid))['compound']\n",
        "    for fileid in movie_reviews.fileids(categories='neg'))/len(movie_reviews.fileids(categories='neg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1053642000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA3sXDx_CTiS",
        "outputId": "188df35f-4875-42f9-f2dd-827ce2bb7aff"
      },
      "source": [
        "sum(sia.polarity_scores(movie_reviews.raw(fileid))['compound']\n",
        "    for fileid in movie_reviews.fileids(categories='pos'))/len(movie_reviews.fileids(categories='pos'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6479031999999998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE6T5yxHCTiS",
        "outputId": "6642d417-244d-4ce4-a7f1-86d5a4b61fc8"
      },
      "source": [
        "nltk.download('twitter_samples')\n",
        "from nltk.corpus import twitter_samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWrrueP-CTiS"
      },
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6cngK2JCTiS",
        "outputId": "075ab95e-2837-402f-8be9-8d4e2832a7de"
      },
      "source": [
        "all_positive_tweets[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)',\n",
              " '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I60KNG4nCTiS",
        "outputId": "cc5069a9-a9c4-4287-c8ee-b4c7148c8330"
      },
      "source": [
        "sia.polarity_scores(random.sample(all_positive_tweets, 1)[0]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.7003, 'neg': 0.0, 'neu': 0.595, 'pos': 0.405}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emJxBcMfCTiS",
        "outputId": "fb5c0f1f-06b2-4dc6-81d4-8b3a4046ed8a"
      },
      "source": [
        "sia.polarity_scores(random.sample(all_negative_tweets, 1)[0]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': -0.4404, 'neg': 0.182, 'neu': 0.818, 'pos': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    }
  ]
}